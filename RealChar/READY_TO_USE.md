# ğŸ‰ RealChar ÄÃ£ Sáºµn SÃ ng!

## âœ… Tráº¡ng ThÃ¡i Há»‡ Thá»‘ng

### Services Ä‘ang cháº¡y:
- âœ… **Ollama** - LLM Server vá»›i model `llama3.2:3b`
- âœ… **Backend** - API server (healthy)
- âœ… **Database** - PostgreSQL (healthy)
- âœ… **Frontend** - Web UI (running)

### Káº¿t Ná»‘i:
- âœ… Backend â†” Ollama: Káº¿t ná»‘i thÃ nh cÃ´ng
- âœ… Frontend â†” Backend: Äang hoáº¡t Ä‘á»™ng

## ğŸŒ Truy Cáº­p

- **Frontend Web UI**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **Ollama API**: http://localhost:11434

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### 1. Má»Ÿ RealChar Web UI
```
Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: http://localhost:3000
```

### 2. Táº¡o Character
- Click "Create Character" hoáº·c "New Character"
- Äiá»n thÃ´ng tin character
- Chá»n model: `llama3.2:3b` (hoáº·c Ä‘á»ƒ máº·c Ä‘á»‹nh)
- Save character

### 3. Báº¯t Äáº§u Chat
- Chá»n character Ä‘Ã£ táº¡o
- Nháº­p tin nháº¯n hoáº·c sá»­ dá»¥ng voice input (náº¿u cÃ³ STT key)
- Nháº­n pháº£n há»“i tá»« AI character

## âš™ï¸ Cáº¥u HÃ¬nh Hiá»‡n Táº¡i

### LLM (Large Language Model)
- **Provider**: Ollama (local)
- **Model**: `llama3.2:3b`
- **URL**: `http://host.docker.internal:11434/v1`

### Speech-to-Text (STT)
- **Provider**: OpenAI Whisper API
- **Cáº§n**: `OPENAI_API_KEY` trong `.env` Ä‘á»ƒ sá»­ dá»¥ng voice input

### Text-to-Speech (TTS)
- **Provider**: Edge TTS (miá»…n phÃ­) hoáº·c ElevenLabs (cáº§n key)

## ğŸ“ LÆ°u Ã

1. **Ollama Service**: Äáº£m báº£o Ollama luÃ´n cháº¡y
   ```bash
   brew services start ollama
   ```

2. **Docker Services**: Náº¿u cáº§n restart
   ```bash
   cd RealChar
   docker compose restart
   ```

3. **API Keys**: Náº¿u muá»‘n dÃ¹ng voice features, cáº§n thÃªm keys vÃ o `.env`:
   - `OPENAI_API_KEY` - cho STT
   - `ELEVENLABS_API_KEY` - cho TTS cao cáº¥p (optional)

## ğŸ› Troubleshooting

### Náº¿u chat khÃ´ng pháº£n há»“i:
1. Kiá»ƒm tra Ollama Ä‘ang cháº¡y:
   ```bash
   brew services list | grep ollama
   ollama list
   ```

2. Kiá»ƒm tra backend logs:
   ```bash
   docker compose logs backend --tail 50
   ```

3. Test Ollama connection tá»« backend:
   ```bash
   docker compose exec backend curl http://host.docker.internal:11434/api/tags
   ```

### Náº¿u muá»‘n Ä‘á»•i model:
```bash
# Pull model má»›i
ollama pull mistral:7b

# Hoáº·c pull model khÃ¡c
ollama pull llama3.2:1b
```

## ğŸ¯ Next Steps

1. Má»Ÿ http://localhost:3000
2. Táº¡o character Ä‘áº§u tiÃªn
3. Báº¯t Ä‘áº§u chat vá»›i AI character!

---

**ChÃºc báº¡n tráº£i nghiá»‡m vui váº» vá»›i RealChar! ğŸš€**

